\hypertarget{overview}{%
\section{Overview}\label{overview}}

In general we decided on the C programming language for implementing
AES. The source code for our algorithm is compiled to a ``Shared
Object'', which is then loaded as a ``dynamically loaded library'' into
a Python wrapper, also referred to as wrapper, which facilitates the
interaction with the algorithm.

The use of two programming languages allows us leverage the advantages
of both, while alleviating some shortcomings that they possess. The
python wrapper provides a command line interface, which enables
encryption and decryption of files and text input. The c source code
describing the implementation of the AES-algorithm, also referred to as
C-core, has test coverage for every function to ensure correctness.

(GRAPHIC?) On calling the wrapper via command line, the program checks,
whether there are already .so-files available to link. If the wrapper
cannot find them it compiles them from the .c-files. After that it links
the libraries and executes the command. It transforms the passed user
input, either file or text, into a padded byte-array, and generates the
key. There is either a 16-byte hex key made available by the user or it
has to be generated via a hash function from a string input by the user.
After the key expansion (in Python) both the key and the byte-array with
the user input get passed on to the C-core. The core gets a pointer to
the array and key. It uses those pointers to transform the
user-input-array in place. After the transformation is finished the
wrapper just needs to output the transformed byte-array.

Since the only differences between AES and Rijndael are the sizes of the
accepted keys and blocks (\cite[p. 31]{rijndael}) the names for both algorithms
will be used synonymously throughout this document.

\hypertarget{language-choices}{%
\section{Language Choices}\label{language-choices}}

We chose to implement the algorithm itself in C, while Python handles
the input and output of our program. This allows us to use both
languages to their full potential, while avoiding problems of both.

\hypertarget{python}{%
\subsection{Python}\label{python}}

Python is a popular (\cite{instack}, \cite{octgit}) multi-paradigm (\cite[p. 6]{learningpython})
programming language. According to \cite{wikipython} it is interpreted,
high-level and general purpose. Combining its high usage with its thirty
years of age it can be considered a mature language and as such boasts a
fair share of success stories (\cite{pythonsuccess}, \cite[p. 9 - 10]{learningpython}. With
over 280000 Packages available via the Python package manager pip it
offers a healthy and extensive ecosystem (\cite{pythoncommunity}).

With our design we are able to make use of Pythons advantages:

\begin{itemize}

\item
  \emph{Readability}: One of Pythons qualities is its ``focus on
  readability, coherence, and software quality in general''
  (\cite[p. 3]{learningpython}). C on the other hand is generally considered to be
  more difficult to understand, especially because of features and
  concepts not found in other languages (\cite[p. 5]{cmodern}). This implementation
  therefore tries to cover as much of the functionality with the easier
  to read Python.
\item
  \emph{Memory safety}: All memory used by our program is allocated by
  python. Since it is a garbage-collected language, the program does not
  have to worry about freeing unused memory. This avoids memory leaks in
  the program. (\cite[p. 18]{learningpython})
\item
  \emph{Performance}: Python is on the slow end of programming
  languages, but that is nearly irrelevant for the purpose it is used in
  the application. The main task is handling input/output and on modern
  computers it should be fast enough to read/write from/to the command
  line or disk, without becoming a bottleneck.
\item
  \emph{Robustness}: The programming language itself is considered
  robust and stable (\cite[p. 9]{learningpython}) input in Python is relatively
  simple and straightforward. There is no undefined behaviour, input
  length or encoding issues the programmer has to worry about (compare
  to \cite{scanf}).
\item
  \emph{Extensibility}: Pythons package manager, import system and large
  standard library makes it easy to add new features to our program.
  Adding password hashing for example could be accomplished by simply
  importing a new package from the standard library and adding a few
  lines of code. This opens up a lot of possibilities for extending the
  functionality of our program in the future. Here Python helps the
  present implementation to cover up for the lack of a package manager
  and a less comprehensive standard library in C(compare
  \cite{cbib} to \cite{pybib}).
\item
  \emph{Productivity}: Python is an dynamically typed (\cite[p. 9]{learningpython}), interpreted language, generating a tight development loop
  uninterrupted by compile times, with almost no delay between writing
  and executing the code. This helps to improve and iterate over the
  code rapidly, motivating a more exploratory and incremental approach
  to program development. Furthermore Python is able to express more
  functionality in less lines of code than other languages, which helps
  with readability and maintainability. ``It is deliberately optimized
  for speed of development'' (\cite[p. 5]{learningpython})
\item
  \emph{Portability}: Most Python code is able to run unmodified on
  ``all major computer platforms''(\cite[p. 4, 17-18]{learningpython}). Combined
  with the portability of C our program is only limited by its ability
  to execute the compilation of the C-core, which for now is bound by
  the ability of Python dispatching the compile command to GCC or Clang,
  which for now was only tested on Ubuntu, but should theoretically work
  on at least all Linux Systems with Python and Clang or GCC installed.
\end{itemize}

\hypertarget{c}{%
\subsection{C}\label{c}}

C is, like Python, one of the most popular programming languages today
(\cite{instack}, \cite{octgit}). It is close to 20 years older than Python though,
dating back to the early 1970s (\cite[p. 2]{cmodern}). It is statically typed
(\cite[p. 40]{modernc}), compiled (\cite[p. 2]{cmodern}), low-level (meaning providing
access to concepts more commonly found on the machine level) (\cite[p. 4]{cmodern}) and provides interfaces for manual memory management, but no build in
garbage collection (\cite[p. 55]{cpointers}). One of the more notable projects
written in C is the Linux kernel, the basis for the widely used Linux
operating system (\cite{kernel}).

C is considered one of the fastest and most efficient languages
(\cite{benchmarkgame}), but is
more error-prone than others (\cite[p. 5]{modernc}). One has to be careful to avoid
so called ``undefined behaviour'', buffer overflows (since C-arrays are
not bounds-checked), and memory management bugs.

A popular example of a serious bug that gets attributed to the fact that
C is more error-prone than other languages is Heartbleed. A programming
mistake so serious, that ``[s]ome might argue that it is the worst
vulnerability found (at least in terms of its potential impact) since
commercial traffic began to flow on the Internet.'' (\cite{forbes}).
\cite{wheeler} sees this as a
direct result of C not including ``any built-in detection or
countermeasure for improper restriction of buffers'' (ch. 3.9) and
states that one of ``the most dangerous widely-used languages for
security-relevant software [is] C''. This type of vulnerability is
``widely used'' often with ``catastrophic effect'' , but ``Using or
switching to almost any other language (other than C, C++, or
Objective-C) would completely eliminate buffer-related vulnerabilities,
including Heartbleed.'' (ch. 3.9.1)

The following list illustrates how the program uses the advantages of C,
while avoiding the shortcomings of the language:

\begin{itemize}

\item
  \emph{Speed}: Since C is considered a fast language (\cite[p. 4]{cmodern}) it is
  not unusual to rewrite calculation intensive parts of programs in C,
  even if the project is written in another language
  (\cite[min. 24:33]{speedup}). Python itself
  uses this architectural concept, interfacing with compiled C code to
  make use of Cs speed advantage for certain tasks, like \cite[p. 7]{learningpython} explains. The author even recommends to create compiled extensions
  for ``domains that do require optimal execution speeds'' and linking
  those back into the Python code. The calculation intensive part of our
  project is clearly the AES encryption itself, especially with growing
  file size. Additionally the architecture of our program allows the C-core to take advantage of '-march='native',
  a compiler-flag that enables tailoring the binary to the features of the underlying CPU,
  resulting in even more performance. And this happens automatically without any input required from the user.
\item
  \emph{no memory management necessary}: Due to the fact that the C-core
  operates on byte-arrays allocated by Python, nothing needs to be
  allocated on heap. Since the rest of the data needed is allocated on
  the stack all memory used is automatically freed after the encryption
  function returns, without the need for the programmer to intervene.
  This avoids memory leaks occurring when allocations on heap are not
  met with a call to free() after the allocated memory is not needed
  anymore. So called double free errors are also made impossible (since
  there is nothing to call `free()' on), meaning there is no risk of
  freeing the same area of memory twice. This error could potentially
  corrupt the programs memory management data structures and lead to a
  crash(\cite[p. 49]{cpointers}).
\item
  \emph{straightforward implementation}: The algorithm described in
  \cite{fips197} translates well to C code. No special imports are needed, no
  hard-to-understand operations are required to be executed and the
  depicetd pseudocode functions map reasonably cleanly to C functions.
  The AES-algorithm itself makes extensive use of
  Galois-Field-operations in $2^8$. Those can be easily expressed
  through the native uint8\_t C-data-type, which represents an unsigned
  byte. Buffer overruns are avoided, because the array AES operates on
  is allocated by Python. Since Python tracks the length of any object
  allocated and since we pass the length of the array as a boundary,
  buffer overruns are highly unlikely. This is one example of how the
  wrapper ensures the data has the right format, leading to less error
  handling and thus keeping the C-core simple.
\item
  \emph{fast compile times}: Since the C-core encompasses only a few
  hundred lines of code it compiles in subsecond time on our development
  machines, even with optimization enabled. This encourages trying new
  things and helps to get quick feedback even for small changes, either
  through the static analyzer of the compiler itself or through the
  included testing libraries. The small and thus fast-compiling C-core
  is only possible by outsorcing all less calculation intensive tasks to
  the wrapper.
\item
  \emph{portability}: C compiles to numerous platforms and operating
  systems. \cite{gccsys} demonstrates how
  many architectures and operating systems can be reached with just one
  compiler. Since the C-core tries to avoid any platform specifics or
  targeting specific compilers, it should not be the limiting factor in
  terms of portability, especially since the reference implementation of
  Python is written partially in C (\cite{pyref}),
  which means Python is not able to target CPU architectures or
  operating systems C cannot run on.
\end{itemize}


\hypertarget{the-wrapper}{%
\section{The wrapper}\label{the-wrapper}}

This chapter describes the Python-wrapper `wrapper.py' in more detail.
Since it is not the focus of the present paper this chapter is kept
shorter than the documentation about the C-core implementing AES.

In general the wrapper is supposed to prepare data and to provide an
interface for the C-core. It is the entry point to the program. The
basic functionality from a user perspective can be broken down into 3
components.

\hypertarget{compiling-the-c-core}{%
\subsection{Compiling the C-core}\label{compiling-the-c-core}}

To guarantee optimal performance and portability the present
implementation compiles the C-source code into linkable binaries on
first startup. The program does get delivered with an empty lib-folder.
On startup, the program tries to link the libraries containing the AES
C-code compiled to binaries from the lib-folder. If it cannot detect
them, it tries to compile them by communicating over the Python
subprocess-library with Clang or GCC. A successful compilation
guarantees that the C-core is able to run on the platform it was
compiled to. Furthermore the compiler may be able to leverage platform
specific optimizations if they are available \footnote{This is mainly accomplished through the \lstinline{-march='native'} flag}. Since compilation time is
short and done only once it is a reasonable way to ensure portability
and performance. Finally it made testing changes to the C-code easier,
since one only has to delete the old library files and run the program
again to trigger a recompile.

\hypertarget{en--and-decryption}{%
\subsection{en- and decryption}\label{en--and-decryption}}

The C-code, once it is compiled to a .so-file, can be dynamically linked
with the Python standard-library ctypes. This allows calling C functions
directly from Python and passing pointers to Python byte arrays. Those
byte arrays can be modified by the called C-code. The wrapper
calls the en- and decrypt functions of the C implementations via the two
python functions ``encrypt'' and ``decrypt'', that both take the byte
array that is supposed to be processed and the expanded keys. The two
functions then prepare the arrays for the ctypes interface and pass them
on to the C-function for en- and decryption, along with the initvals,
which consists of the values for the S-box and the values of the GFMLT
(both generated at program startup) concatenated with the expanded keys.
Since the C-core modifies the byte arrays in place they just get
returned, after the C-function returns.

\hypertarget{interface}{%
\subsection{Interface}\label{interface}}

There are four functions through which the user interacts with the
program: two for text operations and two for file operations. All four
get exposed to the user via the `click'-library, which a following
chapter will explain in more depth. This library passes on the arguments
from the command line to the function it decorates. ITERATION

The text functions, called `te' for `\textbf{t}ext \textbf{e}ncrypt" and
'td' for `\textbf{t}ext \textbf{d}ecrypt' via the command line, simply
encode the received text into a byte array (and add padding or remove
it), expand the key, call the matching en- or decryption function with
both of those arrays and return either the encrypted text in hex or the
decrypted text in utf-8 encoding.

The file functions, called `fe' for `\textbf{f}ile \textbf{e}ncrypt" and
'fd' for `\textbf{f}ext \textbf{d}ecrypt' via the command line, work in
a similar way. They also expand the key, but additionally prepare an
outputfile, by either adding or removing the ``.enc''-file-ending. They
open both the input and output file simultaneously. This helps with very
large files, since they can process them chunk by chunk. This allows for
(theoretically) processing files of unbounded file sizes, since the
program is not limited by the systems RAM. For every chunk the program
reads, it checks if the read length is shorter than the defined length
of a chunk. If that is the case, the program knows, that this is the
last chunk of the file. It either pads the last chunk (in case of
encryption) or removes the padding (in case of decryption), terminates
the read-loop and writes them to disk with the other chunks. During the
process the chunks themselves get passed on to the respective en- or
decryption function, along with the expanded keys.

\hypertarget{possible-areas-of-future-improvements}{%
\section{Possible areas of future
improvements}\label{possible-areas-of-future-improvements}}

This chapter is a collection of ideas, which could bring potential
improvements to the project in the future.

\hypertarget{aes-192-and-aes-256}{%
\subsection{AES-192 and AES-256}\label{aes-192-and-aes-256}}

Currently the implementation only supports AES with key sizes of 128
bits, but it would be possible to also support other lengths of the
standard, namely key lengths of 192 and 256 bits. Changes to the AES
code itself would be minimal since the only difference would be the
number of rounds, which is already a flexible parameter in the
encryption implementation. The prep\_password-function has to be
tweaked, but the used hashing function makes adjusting the key length
easy. The test would have to be modified too, although this modification
seems more like a hassle than a challenge since the logic, that is
already in place for AES-128, only needs to be adjusted for the
additional key sizes. Even modifying the key expansion to accommodate
for two more sizes should be easily doable.

\hypertarget{parallelism}{%
\subsection{Parallelism}\label{parallelism}}

Since AES encrypts blocks independently from each other the algorithm
can be categorized as an so called embarrassingly parallel problem
\cite[p.48]{parallelprog}. Consequently an easy avenue for gaining more
speed seems to be restructuring the program in such a way, that every
available CPU-core gets put to work on a separate series of blocks to
encrypt/decrypt. On short encryption operations in the kilobyte range
this may not deliver a considerable performance increase, but since the
present implementation is able to operate on files of unbounded size,
time saving possibilities become apparent quite fast.

A simple way to archive such parallelism could for example lead through
the OpenMP-library. This library was designed to provide a shared-memory
API that allows the program to execute in parallel and is added into the
program fairly easily (\cite[ch. 5]{parallelprog}. Since the encryption of
multiple blocks can be expressed as a for-loop, OpenMPs `parallel
for'-directive may be an easy way to execute the program on multiple
cores (compare (\cite[ch. 5.5]{parallelprog}).

\hypertarget{t-tables}{%
\subsection{T-tables}\label{t-tables}}

The present implementation already makes use of lookup tables. \cite[p. 59]{rijndael} proposes a method that makes even more extensive use of lookup
tables, which needs only 4 array accesses and 4 bitwise XOR operations
for each round and 4-byte column. They budget in 4kb of memory for the
lookup tables. This is a negligible amount of memory compared to the
gigabytes available on modern x86-systems.

\hypertarget{no-constant-value-calculations}{%
\subsection{No constant value
calculations}\label{no-constant-value-calculations}}

To fulfill the task of this seminar it was explicitly required to (re-)
calculate values, that could as well be hardcoded. The additional space
used by this is calculated as follows: The GFMLT for multiplication with
two and three can be stored in 2 * 256 bytes (multiplication with one
does not need to be stored, since it just results in the unmodified
value itself). The S-box and Inverse S-box are 256 additional bytes
each, which brings us to a total of 1024 additional bytes of memory.
This is considered to be a negligible size increase, but saves on
recalculating the values on program startup.

\hypertarget{block-cipher-mode-of-operation}{%
\subsection{Block cipher mode of
operation}\label{block-cipher-mode-of-operation}}

Due to time constraints, it was not possible to implement a different
block cipher mode of operation, but it is something the current
implementation would greatly benefit from. \ref{encryption-of-multiple-consecutive-blocks} goes more
in-depth regarding this topic.

\hypertarget{file-header-argon2-hashing-algorithm-salt-and-hmac}{%
\subsection{File-header: ARGON2-Hashing algorithm, salt and
HMAC}\label{file-header-argon2-hashing-algorithm-salt-and-hmac}}

At the moment the passwords are hashed with PBKDF2. This algorithm can
unfortunately easily be cracked with the right hardware, like \cite[p. 697]{appcrypt} explains and suggests (on p. 701) using the password hashing
competition winner argon2, which is designed to withstand brute force
attempts by being able to use more memory and parallelism, thus making it
more expensive for an attacker to guess the password. The
argon2-parameters would either have to be hardcoded or attached to the
encrypted text in a header for example.

If such a header would be added, it seems like a logical step to also
add a public salt to the hash parameters specified within. A salt is a
random string, regenerated for each new password, that is hashed along
with the password to prevent any kind of preprocessing attack on the
password hash. The salt itself is stored in the clear. \cite[p. 693]{appcrypt} At
the moment the hash is hardcoded to ``aeskurs'', but in the future would
consist of a randomly generated string from ``os.urandom()''.

The header could also hold the hash for the hash based message
authentication code or short HMAC (\cite[ch. 12.2.3]{paar}). This would ensure
integrity of the message, i.e.~that the encrypted data was not changed,
for example during transit by a malicious third party. This is archived
by hashing the message before transmission in combination with a secret
shared only by the communicating parties (like the encryption-password)
and appending the resulting hash to the message. The receiving party is
then able to verify the integrity of the message by repeating the steps
and comparing the generated and the appended hash.

\cite{moxie} recommends to authenticate first before performing any
cryptographic operation, so a future implementation would probably first
encrypt the message, then hash it and append the hash to the header.
Since we want to ensure that the correct password-hashing parameters
were received, those would be also fed into the HMAC if a future
implementation makes use of said parameters. The HMAC algorithm would
probably a SHA3-variant, as specified in \cite{fips202}, providing the HMAC
with adequate cryptographic strength.
